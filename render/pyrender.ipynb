{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fd2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.linalg import block_diag\n",
    "import trimesh\n",
    "import pyrender\n",
    "from pyrender import RenderFlags\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5626d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapenet_path = Path(\"/mnt/ML/Datasets/shapenet renders/shapenet-orig\")\n",
    "\n",
    "with open('/mnt/ML/Datasets/shapenet renders/pyrender_assets.json', 'r') as f:\n",
    "    asset_ids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8df6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_mat(g, a):\n",
    "    rot = R.from_euler('xy', [g, a], degrees=True)\n",
    "    return block_diag(rot.as_matrix(), 1)\n",
    "\n",
    "def translation_mat(v):\n",
    "    return np.block([[np.identity(3), np.array(v).reshape((-1, 1))],\n",
    "                     [np.zeros((1, 3)), 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdc34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lights():\n",
    "    light = pyrender.SpotLight(color=np.ones(3), \n",
    "                               intensity=8.0,\n",
    "                               innerConeAngle=np.pi/16.0,\n",
    "                               outerConeAngle=np.pi/6.0)\n",
    "    light_poses = [rotation_mat(-40, a) @ translation_mat([0, 0, 2]) for a in [225, 90]]\n",
    "    lights = [(light, light_pose) for light_pose in light_poses]\n",
    "    return lights\n",
    "\n",
    "def get_camera_node(yfov, resolution):\n",
    "    camera = pyrender.PerspectiveCamera(yfov=yfov, aspectRatio=resolution[0] / resolution[1])\n",
    "    camera_node = pyrender.Node(camera=camera, matrix=np.identity(4))\n",
    "    return camera_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8760e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mesh(asset_id):\n",
    "    path = shapenet_path / asset_id / \"models/model_normalized.obj\"\n",
    "    mesh = trimesh.load(path)\n",
    "    mesh.apply_transform(translation_mat(-mesh.centroid))\n",
    "    mesh.apply_transform(translation_mat([0, -mesh.bounds[0, 1], 0]))\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300864d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_from_mesh(mesh):\n",
    "    scene = pyrender.Scene.from_trimesh_scene(mesh, ambient_light=(0.5,)*3, bg_color=(0,)*4)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec05490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_and_save(path, scene, renderer, metadata):\n",
    "    color, depth = renderer.render(scene, flags=RenderFlags.RGBA)\n",
    "    color_img = Image.fromarray(color)\n",
    "    max_depth = 1.6\n",
    "    depth_uint = (255 * depth / max_depth).astype(np.uint8)\n",
    "    depth_img = Image.fromarray(depth_uint)\n",
    "    \n",
    "    (path / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    metadata['rgba_path'] = f\"images/rgba_{metadata['id']:05d}.png\"\n",
    "    metadata['depth_path'] = f\"images/depth_{metadata['id']:05d}.png\"\n",
    "    color_img.save(path / metadata['rgba_path'])\n",
    "    depth_img.save(path / metadata['depth_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2ab4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_asset(renders_path, lights, camera_node, renderer, asset_id, resolution=(256, 256), camera_angles=[], num_random=0, angle_range=((0, -90), (360, 90))):\n",
    "    mesh = get_mesh(asset_id)\n",
    "    scene = scene_from_mesh(mesh)\n",
    "    for light, light_pose in lights:\n",
    "        scene.add(light, pose=light_pose)\n",
    "    scene.add_node(camera_node)\n",
    "    \n",
    "    random_angles = (angle_range[0] + np.random.rand(num_random, 2) * (np.array(angle_range[1]) - angle_range[0])).tolist()\n",
    "    \n",
    "    yfov = camera_node.camera.yfov\n",
    "    xfov = float(2*np.arcsin(camera_node.camera.aspectRatio*np.sin(yfov/2)))\n",
    "    metadatas = [\n",
    "        {\n",
    "            'id': i,\n",
    "            'asset_id': asset_id,\n",
    "            'resolution': resolution,\n",
    "            'x_fov': xfov,\n",
    "            'y_fov': yfov,\n",
    "            'camera_angle': angle,\n",
    "        }\n",
    "        for i, angle in enumerate(camera_angles + random_angles)\n",
    "    ]\n",
    "    \n",
    "    asset_render_path = renders_path / asset_id\n",
    "    asset_render_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for metadata in metadatas:\n",
    "        angle = metadata['camera_angle']\n",
    "        camera_pose = translation_mat([0, 0.1, 0]) @ rotation_mat(-angle[1], angle[0]+180) @ translation_mat([0, 0, 1])\n",
    "        metadata['camera_pose'] = camera_pose.tolist()\n",
    "        scene.set_pose(camera_node, pose=camera_pose)\n",
    "        render_and_save(asset_render_path, scene, renderer, metadata)\n",
    "    \n",
    "    p = np.array([\n",
    "        [1,  0,  0,  0],\n",
    "        [0,  0, -1,  0],\n",
    "        [0,  1,  0,  0],\n",
    "        [0,  0,  0,  1]\n",
    "    ])\n",
    "    transforms = {\n",
    "        'camera_angle_x': xfov,\n",
    "        'camera_angle_y': yfov,\n",
    "        'w': resolution[0],\n",
    "        'h': resolution[1],\n",
    "        'aabb_scale': 0.5,\n",
    "        'frames': [{\n",
    "            'file_path': metadata['rgba_path'],\n",
    "            'transform_matrix': np.matmul(p, metadata['camera_pose']).tolist(),\n",
    "        } for metadata in metadatas],\n",
    "    }\n",
    "    \n",
    "    asset_transforms_path = asset_render_path / 'transforms.json'\n",
    "    with open(asset_transforms_path, 'w') as f:\n",
    "        json.dump(transforms, f, indent=4)\n",
    "\n",
    "    asset_meta_path = asset_render_path / 'metadata.json'\n",
    "    with open(asset_meta_path, 'w') as f:\n",
    "        json.dump(metadatas, f, indent=4)\n",
    "        \n",
    "    return metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14978c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_batch(renders_path, lights, camera_node, renderer, asset_ids, resolution=(256, 256), camera_angles=[], num_random=0, angle_range=((0, -90), (360, 90))):\n",
    "    metadatas = []\n",
    "    for asset_id in tqdm(asset_ids, desc='Rendering...'):\n",
    "        try:\n",
    "            metadata = render_asset(renders_path, lights, camera_node, renderer, asset_id, resolution, camera_angles, num_random, angle_range)\n",
    "            metadatas.append(metadata)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'failed: asset id {asset_id}')\n",
    "            continue\n",
    "    with open(renders_path / 'metadatas.json', 'w') as f:\n",
    "        json.dump(metadatas, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b13c8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering...: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 3456/3456 [5:23:00<00:00,  5.61s/it]\n"
     ]
    }
   ],
   "source": [
    "resolution = (256, 256)\n",
    "camera_angles = [] #[(a, 20) for a in [30, 60, 150]]\n",
    "num_random = 100\n",
    "angle_range = ((0, 0), (360, 35))\n",
    "\n",
    "lights = get_lights()\n",
    "yfov = np.pi / 3.0\n",
    "camera_node = get_camera_node(yfov, resolution)\n",
    "renderer = pyrender.OffscreenRenderer(viewport_width=resolution[0], viewport_height=resolution[1], point_size=1.)\n",
    "batch_asset_ids = asset_ids\n",
    "render_batch(Path('renders_100_views_res_256'), lights, camera_node, renderer, batch_asset_ids, resolution, camera_angles, num_random, angle_range)\n",
    "renderer.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9879f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
